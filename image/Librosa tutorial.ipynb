{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Librosa tutorial\n",
    "\n",
    "- Version: 0.4.3\n",
    "- Tutorial home: https://github.com/librosa/tutorial\n",
    "- Librosa home: http://librosa.github.io/\n",
    "- User forum: https://groups.google.com/forum/#!forum/librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Environments\n",
    "\n",
    "We assume that you have already installed [Anaconda](https://anaconda.org/).\n",
    "\n",
    "If you don't have an environment, create one by following command:\n",
    "\n",
    "```bash\n",
    "conda create --name YOURNAME scipy jupyter ipython\n",
    "```\n",
    "(Replace `YOURNAME` by whatever you want to call the new environment.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then, activate the new environment\n",
    "```bash\n",
    "source activate YOURNAME\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Installing librosa\n",
    "Librosa can then be installed by the following [ðŸ”—]:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge librosa\n",
    "```\n",
    "\n",
    "*NOTE*: Windows need to install audio decoding libraries separately.  We recommend [ffmpeg](http://ffmpeg.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Test drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Start Jupyter:\n",
    "```bash\n",
    "jupyter notebook\n",
    "```\n",
    "and open a new notebook.\n",
    "\n",
    "Then, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.3\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "print(librosa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1355168 22050\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(librosa.util.example_audio_file())\n",
    "print(len(y), sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Documentation!\n",
    "\n",
    "Librosa has extensive documentation with examples.\n",
    "\n",
    "When in doubt, go to http://librosa.github.io/librosa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conventions\n",
    "\n",
    "- All data are basic `numpy` types\n",
    "- **Audio buffers** are called `y`\n",
    "- **Sampling rate** is called `sr`\n",
    "- The last axis is time-like:\n",
    "        y[1000] is the 1001st sample\n",
    "        S[:, 100] is the 101st frame of S\n",
    "- **Defaults** `sr=22050`, `hop_length=512`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Roadmap for today\n",
    "\n",
    "- `librosa.core`\n",
    "- `librosa.feature`\n",
    "- `librosa.display`\n",
    "- `librosa.beat`\n",
    "- `librosa.segment`\n",
    "- `librosa.decompose`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `librosa.core`\n",
    "\n",
    "- Low-level audio processes\n",
    "- Unit conversion\n",
    "- Time-frequency representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To load a signal at its native sampling rate, use `sr=None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710336 44100\n"
     ]
    }
   ],
   "source": [
    "y_orig, sr_orig = librosa.load(librosa.util.example_audio_file(),\n",
    "                     sr=None)\n",
    "print(len(y_orig), sr_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Resampling is easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1355168 22050\n"
     ]
    }
   ],
   "source": [
    "sr = 22050\n",
    "\n",
    "y = librosa.resample(y_orig, sr_orig, sr)\n",
    "\n",
    "print(len(y), sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But what's that in seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.45886621315193\n"
     ]
    }
   ],
   "source": [
    "print(librosa.samples_to_time(len(y), sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Spectral representations\n",
    "\n",
    "Short-time Fourier transform underlies most analysis.\n",
    "\n",
    "`librosa.stft` returns a complex matrix `D`.\n",
    "\n",
    "`D[f, t]` is the FFT value at frequency `f`, time (frame) `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 2647) complex64\n"
     ]
    }
   ],
   "source": [
    "D = librosa.stft(y)\n",
    "print(D.shape, D.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Often, we only care about the magnitude.\n",
    "\n",
    "`D` contains both *magnitude* `S` and *phase* $\\phi$.\n",
    "\n",
    "$$\n",
    "D_{ft} = S_{ft} \\exp\\left(j \\phi_{ft}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 complex64 True\n"
     ]
    }
   ],
   "source": [
    "S, phase = librosa.magphase(D)\n",
    "print(S.dtype, phase.dtype, np.allclose(D, S * phase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constant-Q transforms\n",
    "\n",
    "The CQT gives a logarithmically spaced frequency basis.\n",
    "\n",
    "This representation is more natural for many analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 2647) complex128\n"
     ]
    }
   ],
   "source": [
    "C = librosa.cqt(y, sr=sr)\n",
    "\n",
    "print(C.shape, C.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 0\n",
    "\n",
    "- Load a different audio file\n",
    "- Compute its STFT with a different hop length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-5a30e7b1775d>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-5a30e7b1775d>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    D = librosa.stft(y2, hop_length=   )\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Exercise 0 solution\n",
    "\n",
    "y2, sr2 = librosa.load(   )\n",
    "\n",
    "D = librosa.stft(y2, hop_length=   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `librosa.feature`\n",
    "\n",
    "- Standard features:\n",
    "    - `librosa.feature.melspectrogram`\n",
    "    - `librosa.feature.mfcc`\n",
    "    - `librosa.feature.chroma`\n",
    "    - Lots more...\n",
    "- Feature manipulation:\n",
    "    - `librosa.feature.stack_memory`\n",
    "    - `librosa.feature.delta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Most features work either with audio or STFT input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "melspec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "# Melspec assumes power, not energy as input\n",
    "melspec_stft = librosa.feature.melspectrogram(S=S**2, sr=sr)\n",
    "\n",
    "print(np.allclose(melspec, melspec_stft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `librosa.display`\n",
    "\n",
    "- Plotting routines for spectra and waveforms\n",
    "\n",
    "- **Note**: major overhaul coming in 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Displays are built with matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's make plots pretty\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "\n",
    "# Render figures interactively in the notebook\n",
    "%matplotlib nbagg\n",
    "\n",
    "# IPython gives us an audio widget for playback\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Waveform display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'librosa' has no attribute 'display'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-62ce87cdcaab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'librosa' has no attribute 'display'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "librosa.display.waveplot(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A basic spectrogram display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "librosa.display.specshow(melspec, y_axis='mel', x_axis='time')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "* Pick a feature extractor from the `librosa.feature` submodule and plot the output with `librosa.display.specshow`\n",
    "\n",
    "\n",
    "* **Bonus**: Customize the plot using either `specshow` arguments or `pyplot` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1 solution\n",
    "\n",
    "X = librosa.feature.XX()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "librosa.display.specshow(    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `librosa.beat`\n",
    "\n",
    "- Beat tracking and tempo estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The beat tracker returns the estimated tempo and beat positions (measured in frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "print(tempo)\n",
    "print(beats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's sonify it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "clicks = librosa.clicks(frames=beats, sr=sr, length=len(y))\n",
    "\n",
    "Audio(data=y + clicks, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Beats can be used to downsample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "chroma_sync = librosa.feature.sync(chroma, beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(chroma, y_axis='chroma')\n",
    "plt.ylabel('Full resolution')\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(chroma_sync, y_axis='chroma')\n",
    "plt.ylabel('Beat sync')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `librosa.segment`\n",
    "\n",
    "- Self-similarity / recurrence\n",
    "- Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recurrence matrices encode self-similarity\n",
    "\n",
    "    R[i, j] = similarity between frames (i, j)\n",
    "    \n",
    "Librosa computes recurrence between `k`-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "R = librosa.segment.recurrence_matrix(chroma_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "librosa.display.specshow(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can include affinity weights for each link as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "R2 = librosa.segment.recurrence_matrix(chroma_sync,\n",
    "                                       mode='affinity',\n",
    "                                       sym=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "librosa.display.specshow(R2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "* Plot a recurrence matrix using different  features\n",
    "* **Bonus**: Use a custom distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2 solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `librosa.decompose`\n",
    "\n",
    "- `hpss`: Harmonic-percussive source separation\n",
    "- `nn_filter`: Nearest-neighbor filtering, non-local means, Repet-SIM\n",
    "- `decompose`: NMF, PCA and friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Separating harmonics from percussives is easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_harm, D_perc = librosa.decompose.hpss(D)\n",
    "\n",
    "y_harm = librosa.istft(D_harm)\n",
    "\n",
    "y_perc = librosa.istft(D_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(data=y_harm, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y_perc, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NMF is pretty easy also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "W, H = librosa.decompose.decompose(S, n_components=16, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1), plt.title('W')\n",
    "librosa.display.specshow(librosa.logamplitude(W**2), y_axis='log')\n",
    "plt.subplot(1, 2, 2), plt.title('H')\n",
    "librosa.display.specshow(H, x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Reconstruct the signal using only the first component\n",
    "S_rec = W[:, :1].dot(H[:1, :])\n",
    "\n",
    "y_rec = librosa.istft(S_rec * phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Audio(data=y_rec, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "- Compute a chromagram using only the harmonic component\n",
    "- **Bonus**: run the beat tracker using only the percussive component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrapping up\n",
    "\n",
    "- This was just a brief intro, but there's lots more!\n",
    "\n",
    "- Read the docs: http://librosa.github.io/librosa/\n",
    "- And the example gallery: http://librosa.github.io/librosa_gallery/\n",
    "- We'll be sprinting all day.  Get involved! https://github.com/librosa/librosa/issues/395"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
