{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Defining New autograd Functions\n",
    "----------------------------------------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer and no biases, trained to\n",
    "predict y from x by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation computes the forward pass using operations on PyTorch\n",
    "Variables, and uses PyTorch autograd to compute gradients.\n",
    "\n",
    "In this implementation we implement our own custom autograd function to perform\n",
    "the ReLU function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 40358812.0\n",
      "1 40655856.0\n",
      "2 43313424.0\n",
      "3 39624056.0\n",
      "4 27641106.0\n",
      "5 14660755.0\n",
      "6 6785062.5\n",
      "7 3388318.0\n",
      "8 2053703.375\n",
      "9 1471801.625\n",
      "10 1158314.0\n",
      "11 952621.3125\n",
      "12 800510.9375\n",
      "13 680644.875\n",
      "14 583274.75\n",
      "15 503085.40625\n",
      "16 436339.40625\n",
      "17 380286.3125\n",
      "18 332874.34375\n",
      "19 292812.8125\n",
      "20 258510.609375\n",
      "21 229057.15625\n",
      "22 203636.78125\n",
      "23 181606.015625\n",
      "24 162415.203125\n",
      "25 145655.703125\n",
      "26 130962.0234375\n",
      "27 118076.171875\n",
      "28 106719.984375\n",
      "29 96683.5546875\n",
      "30 87789.9765625\n",
      "31 79862.96875\n",
      "32 72784.9453125\n",
      "33 66447.9921875\n",
      "34 60762.40234375\n",
      "35 55654.28515625\n",
      "36 51051.1015625\n",
      "37 46897.9609375\n",
      "38 43140.5546875\n",
      "39 39734.59765625\n",
      "40 36643.93359375\n",
      "41 33834.15625\n",
      "42 31275.453125\n",
      "43 28940.798828125\n",
      "44 26808.609375\n",
      "45 24857.330078125\n",
      "46 23069.310546875\n",
      "47 21430.6328125\n",
      "48 19926.876953125\n",
      "49 18543.87890625\n",
      "50 17270.4765625\n",
      "51 16097.51953125\n",
      "52 15016.189453125\n",
      "53 14017.427734375\n",
      "54 13094.0283203125\n",
      "55 12239.4990234375\n",
      "56 11447.8515625\n",
      "57 10714.0205078125\n",
      "58 10033.037109375\n",
      "59 9400.361328125\n",
      "60 8812.40234375\n",
      "61 8265.4814453125\n",
      "62 7756.4775390625\n",
      "63 7282.67431640625\n",
      "64 6841.43896484375\n",
      "65 6430.22119140625\n",
      "66 6046.33056640625\n",
      "67 5687.80224609375\n",
      "68 5352.7109375\n",
      "69 5039.4912109375\n",
      "70 4746.3671875\n",
      "71 4471.9140625\n",
      "72 4214.96337890625\n",
      "73 3974.090087890625\n",
      "74 3748.343994140625\n",
      "75 3536.629638671875\n",
      "76 3337.846923828125\n",
      "77 3151.280517578125\n",
      "78 2976.026123046875\n",
      "79 2811.321044921875\n",
      "80 2656.528076171875\n",
      "81 2510.940185546875\n",
      "82 2373.972412109375\n",
      "83 2245.07861328125\n",
      "84 2123.747802734375\n",
      "85 2009.4898681640625\n",
      "86 1901.83984375\n",
      "87 1800.4012451171875\n",
      "88 1704.7529296875\n",
      "89 1614.577392578125\n",
      "90 1529.5904541015625\n",
      "91 1449.4041748046875\n",
      "92 1373.7176513671875\n",
      "93 1302.26171875\n",
      "94 1234.763671875\n",
      "95 1170.9981689453125\n",
      "96 1110.75390625\n",
      "97 1053.813232421875\n",
      "98 999.9765014648438\n",
      "99 949.0571899414062\n",
      "100 900.931640625\n",
      "101 855.428955078125\n",
      "102 812.3767700195312\n",
      "103 771.6294555664062\n",
      "104 733.0433959960938\n",
      "105 696.506591796875\n",
      "106 661.90380859375\n",
      "107 629.1106567382812\n",
      "108 598.0364379882812\n",
      "109 568.5831909179688\n",
      "110 540.6661376953125\n",
      "111 514.2029418945312\n",
      "112 489.1203308105469\n",
      "113 465.33050537109375\n",
      "114 442.7624206542969\n",
      "115 421.3492126464844\n",
      "116 401.0498046875\n",
      "117 381.803955078125\n",
      "118 363.5311584472656\n",
      "119 346.197021484375\n",
      "120 329.739990234375\n",
      "121 314.1041259765625\n",
      "122 299.2486877441406\n",
      "123 285.1307067871094\n",
      "124 271.7145080566406\n",
      "125 258.9934387207031\n",
      "126 246.90330505371094\n",
      "127 235.4091339111328\n",
      "128 224.4791259765625\n",
      "129 214.08436584472656\n",
      "130 204.1923828125\n",
      "131 194.7781982421875\n",
      "132 185.81906127929688\n",
      "133 177.29214477539062\n",
      "134 169.17796325683594\n",
      "135 161.4510955810547\n",
      "136 154.0948486328125\n",
      "137 147.08702087402344\n",
      "138 140.41270446777344\n",
      "139 134.05429077148438\n",
      "140 127.99604797363281\n",
      "141 122.22578430175781\n",
      "142 116.72442626953125\n",
      "143 111.48408508300781\n",
      "144 106.48785400390625\n",
      "145 101.72473907470703\n",
      "146 97.18778228759766\n",
      "147 92.8578872680664\n",
      "148 88.7305908203125\n",
      "149 84.79243469238281\n",
      "150 81.03783416748047\n",
      "151 77.45660400390625\n",
      "152 74.03904724121094\n",
      "153 70.77812957763672\n",
      "154 67.66690826416016\n",
      "155 64.69774627685547\n",
      "156 61.86492919921875\n",
      "157 59.160255432128906\n",
      "158 56.57852554321289\n",
      "159 54.11528015136719\n",
      "160 51.762149810791016\n",
      "161 49.51446533203125\n",
      "162 47.369606018066406\n",
      "163 45.32035446166992\n",
      "164 43.36324691772461\n",
      "165 41.49404525756836\n",
      "166 39.7080078125\n",
      "167 38.002403259277344\n",
      "168 36.37223434448242\n",
      "169 34.81450271606445\n",
      "170 33.325801849365234\n",
      "171 31.903282165527344\n",
      "172 30.542818069458008\n",
      "173 29.243513107299805\n",
      "174 28.00098419189453\n",
      "175 26.813600540161133\n",
      "176 25.678131103515625\n",
      "177 24.592117309570312\n",
      "178 23.553173065185547\n",
      "179 22.559919357299805\n",
      "180 21.61013412475586\n",
      "181 20.70206069946289\n",
      "182 19.832904815673828\n",
      "183 19.001771926879883\n",
      "184 18.206233978271484\n",
      "185 17.445777893066406\n",
      "186 16.717233657836914\n",
      "187 16.020458221435547\n",
      "188 15.353809356689453\n",
      "189 14.715909957885742\n",
      "190 14.104787826538086\n",
      "191 13.5204496383667\n",
      "192 12.960701942443848\n",
      "193 12.424590110778809\n",
      "194 11.912160873413086\n",
      "195 11.421520233154297\n",
      "196 10.950885772705078\n",
      "197 10.500710487365723\n",
      "198 10.069576263427734\n",
      "199 9.6563138961792\n",
      "200 9.260985374450684\n",
      "201 8.881898880004883\n",
      "202 8.518888473510742\n",
      "203 8.171154975891113\n",
      "204 7.8381524085998535\n",
      "205 7.519024848937988\n",
      "206 7.213068008422852\n",
      "207 6.920451641082764\n",
      "208 6.639804840087891\n",
      "209 6.370738506317139\n",
      "210 6.112886905670166\n",
      "211 5.865508079528809\n",
      "212 5.628820419311523\n",
      "213 5.401690483093262\n",
      "214 5.18428897857666\n",
      "215 4.975724697113037\n",
      "216 4.775717735290527\n",
      "217 4.583693027496338\n",
      "218 4.399839878082275\n",
      "219 4.223602294921875\n",
      "220 4.054528713226318\n",
      "221 3.892343521118164\n",
      "222 3.736720085144043\n",
      "223 3.5878846645355225\n",
      "224 3.4447078704833984\n",
      "225 3.3076953887939453\n",
      "226 3.175983190536499\n",
      "227 3.049651622772217\n",
      "228 2.9284727573394775\n",
      "229 2.8122799396514893\n",
      "230 2.701042652130127\n",
      "231 2.5940170288085938\n",
      "232 2.491502046585083\n",
      "233 2.3930435180664062\n",
      "234 2.2987074851989746\n",
      "235 2.207838535308838\n",
      "236 2.1207330226898193\n",
      "237 2.0373306274414062\n",
      "238 1.9572689533233643\n",
      "239 1.8802763223648071\n",
      "240 1.806459903717041\n",
      "241 1.7356743812561035\n",
      "242 1.6675697565078735\n",
      "243 1.6022436618804932\n",
      "244 1.5396472215652466\n",
      "245 1.4793061017990112\n",
      "246 1.4215941429138184\n",
      "247 1.3660531044006348\n",
      "248 1.3128105401992798\n",
      "249 1.261640191078186\n",
      "250 1.2124987840652466\n",
      "251 1.1652752161026\n",
      "252 1.1198335886001587\n",
      "253 1.0763680934906006\n",
      "254 1.0345538854599\n",
      "255 0.994422435760498\n",
      "256 0.9558374285697937\n",
      "257 0.9188739657402039\n",
      "258 0.8833399415016174\n",
      "259 0.849138617515564\n",
      "260 0.8163757920265198\n",
      "261 0.7848609685897827\n",
      "262 0.7544693350791931\n",
      "263 0.7253780364990234\n",
      "264 0.6975137591362\n",
      "265 0.6706042289733887\n",
      "266 0.6447839736938477\n",
      "267 0.6199232339859009\n",
      "268 0.5960360169410706\n",
      "269 0.5731939077377319\n",
      "270 0.551127552986145\n",
      "271 0.5300152897834778\n",
      "272 0.509730875492096\n",
      "273 0.4900979697704315\n",
      "274 0.4714004397392273\n",
      "275 0.45329549908638\n",
      "276 0.43599575757980347\n",
      "277 0.41931775212287903\n",
      "278 0.4033483862876892\n",
      "279 0.38792291283607483\n",
      "280 0.37309783697128296\n",
      "281 0.3589508533477783\n",
      "282 0.3451966643333435\n",
      "283 0.33209937810897827\n",
      "284 0.31939542293548584\n",
      "285 0.3071984648704529\n",
      "286 0.29553747177124023\n",
      "287 0.2842984199523926\n",
      "288 0.2735013961791992\n",
      "289 0.26311826705932617\n",
      "290 0.25311896204948425\n",
      "291 0.24349501729011536\n",
      "292 0.23430824279785156\n",
      "293 0.2254250943660736\n",
      "294 0.21686120331287384\n",
      "295 0.20867297053337097\n",
      "296 0.20074111223220825\n",
      "297 0.19318050146102905\n",
      "298 0.18587937951087952\n",
      "299 0.17884863913059235\n",
      "300 0.1721441000699997\n",
      "301 0.16564035415649414\n",
      "302 0.15938010811805725\n",
      "303 0.15334294736385345\n",
      "304 0.14755447208881378\n",
      "305 0.14198625087738037\n",
      "306 0.13663619756698608\n",
      "307 0.131514310836792\n",
      "308 0.1265866458415985\n",
      "309 0.12182588130235672\n",
      "310 0.1172710433602333\n",
      "311 0.11282992362976074\n",
      "312 0.10859845578670502\n",
      "313 0.1045171245932579\n",
      "314 0.10060116648674011\n",
      "315 0.09683110564947128\n",
      "316 0.09318370372056961\n",
      "317 0.08972452580928802\n",
      "318 0.08634957671165466\n",
      "319 0.08314685523509979\n",
      "320 0.08002243936061859\n",
      "321 0.07701034098863602\n",
      "322 0.07412324845790863\n",
      "323 0.07136418670415878\n",
      "324 0.06868810951709747\n",
      "325 0.06611573696136475\n",
      "326 0.06363662332296371\n",
      "327 0.06127755343914032\n",
      "328 0.05897273123264313\n",
      "329 0.05679754912853241\n",
      "330 0.05468980222940445\n",
      "331 0.052637580782175064\n",
      "332 0.05068357288837433\n",
      "333 0.04881414398550987\n",
      "334 0.04698862135410309\n",
      "335 0.045247163623571396\n",
      "336 0.04356006160378456\n",
      "337 0.04196072369813919\n",
      "338 0.040381766855716705\n",
      "339 0.03890566527843475\n",
      "340 0.03745453804731369\n",
      "341 0.0360579788684845\n",
      "342 0.03473193198442459\n",
      "343 0.03346262499690056\n",
      "344 0.03219335526227951\n",
      "345 0.031018713489174843\n",
      "346 0.02987128309905529\n",
      "347 0.028781427070498466\n",
      "348 0.027715036645531654\n",
      "349 0.026693934574723244\n",
      "350 0.02571101300418377\n",
      "351 0.024763060733675957\n",
      "352 0.023858053609728813\n",
      "353 0.022982222959399223\n",
      "354 0.02214316464960575\n",
      "355 0.02132650837302208\n",
      "356 0.02053857035934925\n",
      "357 0.019799068570137024\n",
      "358 0.019077418372035027\n",
      "359 0.018382320180535316\n",
      "360 0.01771296188235283\n",
      "361 0.017068013548851013\n",
      "362 0.01643899455666542\n",
      "363 0.0158389825373888\n",
      "364 0.015260161831974983\n",
      "365 0.014727874659001827\n",
      "366 0.01419480424374342\n",
      "367 0.013674069195985794\n",
      "368 0.013183661736547947\n",
      "369 0.012701275758445263\n",
      "370 0.012251167558133602\n",
      "371 0.0118093928322196\n",
      "372 0.011394861154258251\n",
      "373 0.010976411402225494\n",
      "374 0.010581410489976406\n",
      "375 0.010202952660620213\n",
      "376 0.009841336868703365\n",
      "377 0.00949174351990223\n",
      "378 0.009148986078798771\n",
      "379 0.008826523087918758\n",
      "380 0.00850819330662489\n",
      "381 0.008205596357584\n",
      "382 0.007919171825051308\n",
      "383 0.007643970660865307\n",
      "384 0.007376161403954029\n",
      "385 0.0071144262328743935\n",
      "386 0.006865908391773701\n",
      "387 0.006622882094234228\n",
      "388 0.006392098031938076\n",
      "389 0.006168506108224392\n",
      "390 0.0059520709328353405\n",
      "391 0.005748261231929064\n",
      "392 0.005551041569560766\n",
      "393 0.005360218230634928\n",
      "394 0.005180081818252802\n",
      "395 0.005002176854759455\n",
      "396 0.004829379264265299\n",
      "397 0.0046664075925946236\n",
      "398 0.0045077078975737095\n",
      "399 0.004354402888566256\n",
      "400 0.004206271842122078\n",
      "401 0.00406894413754344\n",
      "402 0.003932811785489321\n",
      "403 0.003802028950303793\n",
      "404 0.0036756321787834167\n",
      "405 0.0035495958290994167\n",
      "406 0.003432538593187928\n",
      "407 0.0033194757997989655\n",
      "408 0.0032092803157866\n",
      "409 0.0031060106121003628\n",
      "410 0.0030020899139344692\n",
      "411 0.0029011545702815056\n",
      "412 0.002807551994919777\n",
      "413 0.002718948293477297\n",
      "414 0.0026340261101722717\n",
      "415 0.002549156080931425\n",
      "416 0.002469893079251051\n",
      "417 0.002390229143202305\n",
      "418 0.0023166772443801165\n",
      "419 0.0022431197576224804\n",
      "420 0.0021715653128921986\n",
      "421 0.002105100080370903\n",
      "422 0.002038730774074793\n",
      "423 0.0019774516113102436\n",
      "424 0.0019161863019689918\n",
      "425 0.00185863405931741\n",
      "426 0.0018013641238212585\n",
      "427 0.00174815917853266\n",
      "428 0.0016951223369687796\n",
      "429 0.0016459807520732284\n",
      "430 0.0015977779403328896\n",
      "431 0.0015517020365223289\n",
      "432 0.0015077865682542324\n",
      "433 0.0014657889259979129\n",
      "434 0.0014216643758118153\n",
      "435 0.0013824158813804388\n",
      "436 0.001341638038866222\n",
      "437 0.001306581194512546\n",
      "438 0.0012716527562588453\n",
      "439 0.001235377974808216\n",
      "440 0.0012012965744361281\n",
      "441 0.001166915986686945\n",
      "442 0.0011345442617312074\n",
      "443 0.001103965099900961\n",
      "444 0.0010751381050795317\n",
      "445 0.0010450560366734862\n",
      "446 0.00101949623785913\n",
      "447 0.0009905439801514149\n",
      "448 0.0009662033407948911\n",
      "449 0.0009406190947629511\n",
      "450 0.0009156480082310736\n",
      "451 0.0008921431726776063\n",
      "452 0.0008688134257681668\n",
      "453 0.0008473802008666098\n",
      "454 0.0008261631592176855\n",
      "455 0.0008048142772167921\n",
      "456 0.0007840053294785321\n",
      "457 0.0007632222841493785\n",
      "458 0.0007460321066901088\n",
      "459 0.0007278478587977588\n",
      "460 0.0007105260156095028\n",
      "461 0.0006936722784303129\n",
      "462 0.0006771052721887827\n",
      "463 0.0006620052736252546\n",
      "464 0.0006467698840424418\n",
      "465 0.0006308890879154205\n",
      "466 0.0006152880960144103\n",
      "467 0.000602724205236882\n",
      "468 0.0005886327708140016\n",
      "469 0.0005756840109825134\n",
      "470 0.0005625021876767278\n",
      "471 0.0005491967895068228\n",
      "472 0.0005365745746530592\n",
      "473 0.000526478688698262\n",
      "474 0.0005145620671100914\n",
      "475 0.000503662449773401\n",
      "476 0.0004929016577079892\n",
      "477 0.0004818299494218081\n",
      "478 0.0004722404992207885\n",
      "479 0.0004616432706825435\n",
      "480 0.0004515333566814661\n",
      "481 0.00044175126822665334\n",
      "482 0.0004327599599491805\n",
      "483 0.00042433783528394997\n",
      "484 0.0004155280767008662\n",
      "485 0.000407675513997674\n",
      "486 0.00039924070006236434\n",
      "487 0.00039061473216861486\n",
      "488 0.00038299820153042674\n",
      "489 0.0003747153386939317\n",
      "490 0.00036783612449653447\n",
      "491 0.00036111174267716706\n",
      "492 0.000352780451066792\n",
      "493 0.0003474078548606485\n",
      "494 0.0003406776813790202\n",
      "495 0.0003341811534482986\n",
      "496 0.00032728517544455826\n",
      "497 0.0003213723248336464\n",
      "498 0.0003156783932354301\n",
      "499 0.0003104821080341935\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # To apply our Function, we use Function.apply method. We alias this as 'relu'.\n",
    "    relu = MyReLU.apply\n",
    "\n",
    "    # Forward pass: compute predicted y using operations; we compute\n",
    "    # ReLU using our custom autograd operation.\n",
    "    y_pred = relu(x.mm(w1)).mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
